# Comparing `tmp/data_gradients-0.1.2-py3-none-any.whl.zip` & `tmp/data_gradients-0.1.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,121 +1,121 @@
-Zip file size: 415174 bytes, number of entries: 119
--rw-r--r--  2.0 unx       22 b- defN 23-Jul-10 11:27 data_gradients/__init__.py
--rw-r--r--  2.0 unx      221 b- defN 23-Jul-10 11:27 data_gradients/requirements.txt
--rw-r--r--  2.0 unx      231 b- defN 23-Jul-10 11:27 data_gradients/assets/__init__.py
--rw-r--r--  2.0 unx     2755 b- defN 23-Jul-10 11:27 data_gradients/assets/assets_container.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/assets/css/test.css
--rw-r--r--  2.0 unx     3244 b- defN 23-Jul-10 11:27 data_gradients/assets/html/basic_info_fe.html
--rw-r--r--  2.0 unx     8301 b- defN 23-Jul-10 11:27 data_gradients/assets/html/doc_template.html
--rw-r--r--  2.0 unx      123 b- defN 23-Jul-10 11:27 data_gradients/assets/html/test.html
--rw-r--r--  2.0 unx    51292 b- defN 23-Jul-10 11:27 data_gradients/assets/images/chart_demo.png
--rw-r--r--  2.0 unx   139838 b- defN 23-Jul-10 11:27 data_gradients/assets/images/info.png
--rw-r--r--  2.0 unx    36081 b- defN 23-Jul-10 11:27 data_gradients/assets/images/logo.png
--rw-r--r--  2.0 unx    75086 b- defN 23-Jul-10 11:27 data_gradients/assets/images/warning.png
--rw-r--r--  2.0 unx      333 b- defN 23-Jul-10 11:27 data_gradients/assets/text/lorem_ipsum.txt
--rw-r--r--  2.0 unx       12 b- defN 23-Jul-10 11:27 data_gradients/assets/text/test.txt
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/__init__.py
--rw-r--r--  2.0 unx     1636 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/base.py
--rw-r--r--  2.0 unx     1125 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/detection.py
--rw-r--r--  2.0 unx     1236 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/segmentation.py
--rw-r--r--  2.0 unx     1155 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/adapters/__init__.py
--rw-r--r--  2.0 unx     4621 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/adapters/dataset_adapter.py
--rw-r--r--  2.0 unx     6698 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/adapters/tensor_extractor.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/formatters/__init__.py
--rw-r--r--  2.0 unx      725 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/formatters/base.py
--rw-r--r--  2.0 unx     9044 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/formatters/detection.py
--rw-r--r--  2.0 unx     7181 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/formatters/segmentation.py
--rw-r--r--  2.0 unx     1912 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/formatters/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/preprocessors/__init__.py
--rw-r--r--  2.0 unx      994 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/preprocessors/base.py
--rw-r--r--  2.0 unx     5189 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/preprocessors/contours.py
--rw-r--r--  2.0 unx     2527 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/preprocessors/detection.py
--rw-r--r--  2.0 unx     1836 b- defN 23-Jul-10 11:27 data_gradients/batch_processors/preprocessors/segmentation.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/common/__init__.py
--rw-r--r--  2.0 unx       66 b- defN 23-Jul-10 11:27 data_gradients/common/decorators/__init__.py
--rw-r--r--  2.0 unx     1314 b- defN 23-Jul-10 11:27 data_gradients/common/decorators/decorators.py
--rw-r--r--  2.0 unx      140 b- defN 23-Jul-10 11:27 data_gradients/common/factories/__init__.py
--rw-r--r--  2.0 unx     3694 b- defN 23-Jul-10 11:27 data_gradients/common/factories/base_factory.py
--rw-r--r--  2.0 unx      206 b- defN 23-Jul-10 11:27 data_gradients/common/factories/feature_extractors_factory.py
--rw-r--r--  2.0 unx      569 b- defN 23-Jul-10 11:27 data_gradients/common/factories/list_factory.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/common/registry/__init__.py
--rw-r--r--  2.0 unx     1245 b- defN 23-Jul-10 11:27 data_gradients/common/registry/registry.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/config/__init__.py
--rw-r--r--  2.0 unx      903 b- defN 23-Jul-10 11:27 data_gradients/config/detection.yaml
--rw-r--r--  2.0 unx      954 b- defN 23-Jul-10 11:27 data_gradients/config/segmentation.yaml
--rw-r--r--  2.0 unx     6641 b- defN 23-Jul-10 11:27 data_gradients/config/utils.py
--rw-r--r--  2.0 unx      157 b- defN 23-Jul-10 11:27 data_gradients/config/data/__init__.py
--rw-r--r--  2.0 unx     8725 b- defN 23-Jul-10 11:27 data_gradients/config/data/caching_utils.py
--rw-r--r--  2.0 unx     8676 b- defN 23-Jul-10 11:27 data_gradients/config/data/data_config.py
--rw-r--r--  2.0 unx     2894 b- defN 23-Jul-10 11:27 data_gradients/config/data/questions.py
--rw-r--r--  2.0 unx      503 b- defN 23-Jul-10 11:27 data_gradients/config/data/typing.py
--rw-r--r--  2.0 unx     9524 b- defN 23-Jul-10 11:27 data_gradients/datasets/FolderProcessor.py
--rw-r--r--  2.0 unx      288 b- defN 23-Jul-10 11:27 data_gradients/datasets/__init__.py
--rw-r--r--  2.0 unx     2820 b- defN 23-Jul-10 11:27 data_gradients/datasets/base_dataset.py
--rw-r--r--  2.0 unx     2265 b- defN 23-Jul-10 11:27 data_gradients/datasets/bdd_dataset.py
--rw-r--r--  2.0 unx      859 b- defN 23-Jul-10 11:27 data_gradients/datasets/utils.py
--rw-r--r--  2.0 unx      386 b- defN 23-Jul-10 11:27 data_gradients/datasets/detection/__init__.py
--rw-r--r--  2.0 unx     4037 b- defN 23-Jul-10 11:27 data_gradients/datasets/detection/voc_detection_dataset.py
--rw-r--r--  2.0 unx     6583 b- defN 23-Jul-10 11:27 data_gradients/datasets/detection/voc_format_detection_dataset.py
--rw-r--r--  2.0 unx     6987 b- defN 23-Jul-10 11:27 data_gradients/datasets/detection/yolo_format_detection_dataset.py
--rw-r--r--  2.0 unx     1605 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/__init__.py
--rw-r--r--  2.0 unx     1461 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/abstract_feature_extractor.py
--rw-r--r--  2.0 unx     4445 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/features.py
--rw-r--r--  2.0 unx     4256 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/utils.py
--rw-r--r--  2.0 unx      394 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/common/__init__.py
--rw-r--r--  2.0 unx     2337 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/common/heatmap.py
--rw-r--r--  2.0 unx     3740 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/common/image_average_brightness.py
--rw-r--r--  2.0 unx     4490 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/common/image_color_distribution.py
--rw-r--r--  2.0 unx    13444 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/common/image_duplicates.py
--rw-r--r--  2.0 unx     3362 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/common/image_resolution.py
--rw-r--r--  2.0 unx     3218 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/common/sample_visualization.py
--rw-r--r--  2.0 unx     5016 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/common/summary.py
--rw-r--r--  2.0 unx      790 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/__init__.py
--rw-r--r--  2.0 unx     4124 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/bounding_boxes_area.py
--rw-r--r--  2.0 unx     5754 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/bounding_boxes_iou.py
--rw-r--r--  2.0 unx     2138 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/bounding_boxes_per_image_count.py
--rw-r--r--  2.0 unx     2877 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/bounding_boxes_resolution.py
--rw-r--r--  2.0 unx     4036 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/classes_frequency.py
--rw-r--r--  2.0 unx     4232 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/classes_frequency_per_image.py
--rw-r--r--  2.0 unx     2596 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/classes_heatmap_per_class.py
--rw-r--r--  2.0 unx     1981 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/object_detection/sample_visualization.py
--rw-r--r--  2.0 unx      958 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/__init__.py
--rw-r--r--  2.0 unx     4209 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/bounding_boxes_area.py
--rw-r--r--  2.0 unx     2809 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/bounding_boxes_resolution.py
--rw-r--r--  2.0 unx     4124 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/classes_frequency.py
--rw-r--r--  2.0 unx     4251 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/classes_frequency_per_image.py
--rw-r--r--  2.0 unx     2645 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/classes_heatmap_per_class.py
--rw-r--r--  2.0 unx     2135 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/component_frequency_per_image.py
--rw-r--r--  2.0 unx     2302 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/components_convexity.py
--rw-r--r--  2.0 unx     3807 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/components_erosion.py
--rw-r--r--  2.0 unx     2674 b- defN 23-Jul-10 11:27 data_gradients/feature_extractors/segmentation/sample_visualization.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/managers/__init__.py
--rw-r--r--  2.0 unx    12234 b- defN 23-Jul-10 11:27 data_gradients/managers/abstract_manager.py
--rw-r--r--  2.0 unx     6065 b- defN 23-Jul-10 11:27 data_gradients/managers/detection_manager.py
--rw-r--r--  2.0 unx     5951 b- defN 23-Jul-10 11:27 data_gradients/managers/segmentation_manager.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/utils/__init__.py
--rw-r--r--  2.0 unx     2819 b- defN 23-Jul-10 11:27 data_gradients/utils/detection.py
--rw-r--r--  2.0 unx     1052 b- defN 23-Jul-10 11:27 data_gradients/utils/image_processing.py
--rw-r--r--  2.0 unx     2550 b- defN 23-Jul-10 11:27 data_gradients/utils/pdf_writer.py
--rw-r--r--  2.0 unx     3705 b- defN 23-Jul-10 11:27 data_gradients/utils/summary_writer.py
--rw-r--r--  2.0 unx     2561 b- defN 23-Jul-10 11:27 data_gradients/utils/utils.py
--rw-r--r--  2.0 unx      169 b- defN 23-Jul-10 11:27 data_gradients/utils/common/__init__.py
--rw-r--r--  2.0 unx      249 b- defN 23-Jul-10 11:27 data_gradients/utils/data_classes/__init__.py
--rw-r--r--  2.0 unx      260 b- defN 23-Jul-10 11:27 data_gradients/utils/data_classes/contour.py
--rw-r--r--  2.0 unx     3088 b- defN 23-Jul-10 11:27 data_gradients/utils/data_classes/data_samples.py
--rw-r--r--  2.0 unx     3975 b- defN 23-Jul-10 11:27 data_gradients/utils/data_classes/extractor_results.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:27 data_gradients/visualize/__init__.py
--rw-r--r--  2.0 unx     5101 b- defN 23-Jul-10 11:27 data_gradients/visualize/images.py
--rw-r--r--  2.0 unx    11756 b- defN 23-Jul-10 11:27 data_gradients/visualize/plot_options.py
--rw-r--r--  2.0 unx    16753 b- defN 23-Jul-10 11:27 data_gradients/visualize/seaborn_renderer.py
--rw-r--r--  2.0 unx     1165 b- defN 23-Jul-10 11:27 data_gradients/visualize/utils.py
--rw-r--r--  2.0 unx       96 b- defN 23-Jul-10 11:27 data_gradients/visualize/detection/__init__.py
--rw-r--r--  2.0 unx     4075 b- defN 23-Jul-10 11:27 data_gradients/visualize/detection/detection.py
--rw-r--r--  2.0 unx     4862 b- defN 23-Jul-10 11:27 data_gradients/visualize/detection/detection_legend.py
--rw-r--r--  2.0 unx     1432 b- defN 23-Jul-10 11:27 data_gradients/visualize/detection/utils.py
--rw-r--r--  2.0 unx    11341 b- defN 23-Jul-10 11:32 data_gradients-0.1.2.dist-info/LICENSE.md
--rw-r--r--  2.0 unx    10637 b- defN 23-Jul-10 11:32 data_gradients-0.1.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jul-10 11:32 data_gradients-0.1.2.dist-info/WHEEL
--rw-r--r--  2.0 unx       15 b- defN 23-Jul-10 11:32 data_gradients-0.1.2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    12527 b- defN 23-Jul-10 11:32 data_gradients-0.1.2.dist-info/RECORD
-119 files, 664594 bytes uncompressed, 394400 bytes compressed:  40.7%
+Zip file size: 416335 bytes, number of entries: 119
+-rw-r--r--  2.0 unx       22 b- defN 23-Jul-12 11:51 data_gradients/__init__.py
+-rw-r--r--  2.0 unx      221 b- defN 23-Jul-12 11:51 data_gradients/requirements.txt
+-rw-r--r--  2.0 unx      231 b- defN 23-Jul-12 11:51 data_gradients/assets/__init__.py
+-rw-r--r--  2.0 unx     2755 b- defN 23-Jul-12 11:51 data_gradients/assets/assets_container.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/assets/css/test.css
+-rw-r--r--  2.0 unx     3244 b- defN 23-Jul-12 11:51 data_gradients/assets/html/basic_info_fe.html
+-rw-r--r--  2.0 unx     8762 b- defN 23-Jul-12 11:51 data_gradients/assets/html/doc_template.html
+-rw-r--r--  2.0 unx      123 b- defN 23-Jul-12 11:51 data_gradients/assets/html/test.html
+-rw-r--r--  2.0 unx    51292 b- defN 23-Jul-12 11:51 data_gradients/assets/images/chart_demo.png
+-rw-r--r--  2.0 unx   139838 b- defN 23-Jul-12 11:51 data_gradients/assets/images/info.png
+-rw-r--r--  2.0 unx    36081 b- defN 23-Jul-12 11:51 data_gradients/assets/images/logo.png
+-rw-r--r--  2.0 unx    75086 b- defN 23-Jul-12 11:51 data_gradients/assets/images/warning.png
+-rw-r--r--  2.0 unx      333 b- defN 23-Jul-12 11:51 data_gradients/assets/text/lorem_ipsum.txt
+-rw-r--r--  2.0 unx       12 b- defN 23-Jul-12 11:51 data_gradients/assets/text/test.txt
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/__init__.py
+-rw-r--r--  2.0 unx     1636 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/base.py
+-rw-r--r--  2.0 unx     1125 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/detection.py
+-rw-r--r--  2.0 unx     1236 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/segmentation.py
+-rw-r--r--  2.0 unx     1155 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/adapters/__init__.py
+-rw-r--r--  2.0 unx     4621 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/adapters/dataset_adapter.py
+-rw-r--r--  2.0 unx     6698 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/adapters/tensor_extractor.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/formatters/__init__.py
+-rw-r--r--  2.0 unx      725 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/formatters/base.py
+-rw-r--r--  2.0 unx     9044 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/formatters/detection.py
+-rw-r--r--  2.0 unx     7516 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/formatters/segmentation.py
+-rw-r--r--  2.0 unx     1912 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/formatters/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/preprocessors/__init__.py
+-rw-r--r--  2.0 unx      994 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/preprocessors/base.py
+-rw-r--r--  2.0 unx     5189 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/preprocessors/contours.py
+-rw-r--r--  2.0 unx     2527 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/preprocessors/detection.py
+-rw-r--r--  2.0 unx     1836 b- defN 23-Jul-12 11:51 data_gradients/batch_processors/preprocessors/segmentation.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/common/__init__.py
+-rw-r--r--  2.0 unx       66 b- defN 23-Jul-12 11:51 data_gradients/common/decorators/__init__.py
+-rw-r--r--  2.0 unx     1314 b- defN 23-Jul-12 11:51 data_gradients/common/decorators/decorators.py
+-rw-r--r--  2.0 unx      140 b- defN 23-Jul-12 11:51 data_gradients/common/factories/__init__.py
+-rw-r--r--  2.0 unx     3694 b- defN 23-Jul-12 11:51 data_gradients/common/factories/base_factory.py
+-rw-r--r--  2.0 unx      206 b- defN 23-Jul-12 11:51 data_gradients/common/factories/feature_extractors_factory.py
+-rw-r--r--  2.0 unx      569 b- defN 23-Jul-12 11:51 data_gradients/common/factories/list_factory.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/common/registry/__init__.py
+-rw-r--r--  2.0 unx     1245 b- defN 23-Jul-12 11:51 data_gradients/common/registry/registry.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/config/__init__.py
+-rw-r--r--  2.0 unx      903 b- defN 23-Jul-12 11:51 data_gradients/config/detection.yaml
+-rw-r--r--  2.0 unx      954 b- defN 23-Jul-12 11:51 data_gradients/config/segmentation.yaml
+-rw-r--r--  2.0 unx     6641 b- defN 23-Jul-12 11:51 data_gradients/config/utils.py
+-rw-r--r--  2.0 unx      157 b- defN 23-Jul-12 11:51 data_gradients/config/data/__init__.py
+-rw-r--r--  2.0 unx     8725 b- defN 23-Jul-12 11:51 data_gradients/config/data/caching_utils.py
+-rw-r--r--  2.0 unx     8676 b- defN 23-Jul-12 11:51 data_gradients/config/data/data_config.py
+-rw-r--r--  2.0 unx     2816 b- defN 23-Jul-12 11:51 data_gradients/config/data/questions.py
+-rw-r--r--  2.0 unx      503 b- defN 23-Jul-12 11:51 data_gradients/config/data/typing.py
+-rw-r--r--  2.0 unx     9524 b- defN 23-Jul-12 11:51 data_gradients/datasets/FolderProcessor.py
+-rw-r--r--  2.0 unx      288 b- defN 23-Jul-12 11:51 data_gradients/datasets/__init__.py
+-rw-r--r--  2.0 unx     2820 b- defN 23-Jul-12 11:51 data_gradients/datasets/base_dataset.py
+-rw-r--r--  2.0 unx     2265 b- defN 23-Jul-12 11:51 data_gradients/datasets/bdd_dataset.py
+-rw-r--r--  2.0 unx      859 b- defN 23-Jul-12 11:51 data_gradients/datasets/utils.py
+-rw-r--r--  2.0 unx      386 b- defN 23-Jul-12 11:51 data_gradients/datasets/detection/__init__.py
+-rw-r--r--  2.0 unx     4037 b- defN 23-Jul-12 11:51 data_gradients/datasets/detection/voc_detection_dataset.py
+-rw-r--r--  2.0 unx     6583 b- defN 23-Jul-12 11:51 data_gradients/datasets/detection/voc_format_detection_dataset.py
+-rw-r--r--  2.0 unx     6987 b- defN 23-Jul-12 11:51 data_gradients/datasets/detection/yolo_format_detection_dataset.py
+-rw-r--r--  2.0 unx     1605 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/__init__.py
+-rw-r--r--  2.0 unx     1461 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/abstract_feature_extractor.py
+-rw-r--r--  2.0 unx     4445 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/features.py
+-rw-r--r--  2.0 unx     4256 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/utils.py
+-rw-r--r--  2.0 unx      394 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/common/__init__.py
+-rw-r--r--  2.0 unx     2337 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/common/heatmap.py
+-rw-r--r--  2.0 unx     3740 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/common/image_average_brightness.py
+-rw-r--r--  2.0 unx     4490 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/common/image_color_distribution.py
+-rw-r--r--  2.0 unx    13444 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/common/image_duplicates.py
+-rw-r--r--  2.0 unx     3362 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/common/image_resolution.py
+-rw-r--r--  2.0 unx     3218 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/common/sample_visualization.py
+-rw-r--r--  2.0 unx     5016 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/common/summary.py
+-rw-r--r--  2.0 unx      790 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/__init__.py
+-rw-r--r--  2.0 unx     4124 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/bounding_boxes_area.py
+-rw-r--r--  2.0 unx     5754 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/bounding_boxes_iou.py
+-rw-r--r--  2.0 unx     2138 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/bounding_boxes_per_image_count.py
+-rw-r--r--  2.0 unx     2877 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/bounding_boxes_resolution.py
+-rw-r--r--  2.0 unx     4036 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/classes_frequency.py
+-rw-r--r--  2.0 unx     4232 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/classes_frequency_per_image.py
+-rw-r--r--  2.0 unx     2596 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/classes_heatmap_per_class.py
+-rw-r--r--  2.0 unx     1981 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/object_detection/sample_visualization.py
+-rw-r--r--  2.0 unx      958 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/__init__.py
+-rw-r--r--  2.0 unx     4209 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/bounding_boxes_area.py
+-rw-r--r--  2.0 unx     2809 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/bounding_boxes_resolution.py
+-rw-r--r--  2.0 unx     4124 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/classes_frequency.py
+-rw-r--r--  2.0 unx     4251 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/classes_frequency_per_image.py
+-rw-r--r--  2.0 unx     2645 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/classes_heatmap_per_class.py
+-rw-r--r--  2.0 unx     2135 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/component_frequency_per_image.py
+-rw-r--r--  2.0 unx     2302 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/components_convexity.py
+-rw-r--r--  2.0 unx     3807 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/components_erosion.py
+-rw-r--r--  2.0 unx     2674 b- defN 23-Jul-12 11:51 data_gradients/feature_extractors/segmentation/sample_visualization.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/managers/__init__.py
+-rw-r--r--  2.0 unx    12869 b- defN 23-Jul-12 11:51 data_gradients/managers/abstract_manager.py
+-rw-r--r--  2.0 unx     6077 b- defN 23-Jul-12 11:51 data_gradients/managers/detection_manager.py
+-rw-r--r--  2.0 unx     5962 b- defN 23-Jul-12 11:51 data_gradients/managers/segmentation_manager.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/utils/__init__.py
+-rw-r--r--  2.0 unx     2819 b- defN 23-Jul-12 11:51 data_gradients/utils/detection.py
+-rw-r--r--  2.0 unx     1052 b- defN 23-Jul-12 11:51 data_gradients/utils/image_processing.py
+-rw-r--r--  2.0 unx     2550 b- defN 23-Jul-12 11:51 data_gradients/utils/pdf_writer.py
+-rw-r--r--  2.0 unx     3705 b- defN 23-Jul-12 11:51 data_gradients/utils/summary_writer.py
+-rw-r--r--  2.0 unx     4024 b- defN 23-Jul-12 11:51 data_gradients/utils/utils.py
+-rw-r--r--  2.0 unx      169 b- defN 23-Jul-12 11:51 data_gradients/utils/common/__init__.py
+-rw-r--r--  2.0 unx      249 b- defN 23-Jul-12 11:51 data_gradients/utils/data_classes/__init__.py
+-rw-r--r--  2.0 unx      260 b- defN 23-Jul-12 11:51 data_gradients/utils/data_classes/contour.py
+-rw-r--r--  2.0 unx     3088 b- defN 23-Jul-12 11:51 data_gradients/utils/data_classes/data_samples.py
+-rw-r--r--  2.0 unx     3975 b- defN 23-Jul-12 11:51 data_gradients/utils/data_classes/extractor_results.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-12 11:51 data_gradients/visualize/__init__.py
+-rw-r--r--  2.0 unx     5101 b- defN 23-Jul-12 11:51 data_gradients/visualize/images.py
+-rw-r--r--  2.0 unx    11756 b- defN 23-Jul-12 11:51 data_gradients/visualize/plot_options.py
+-rw-r--r--  2.0 unx    16753 b- defN 23-Jul-12 11:51 data_gradients/visualize/seaborn_renderer.py
+-rw-r--r--  2.0 unx     1165 b- defN 23-Jul-12 11:51 data_gradients/visualize/utils.py
+-rw-r--r--  2.0 unx       96 b- defN 23-Jul-12 11:51 data_gradients/visualize/detection/__init__.py
+-rw-r--r--  2.0 unx     4075 b- defN 23-Jul-12 11:51 data_gradients/visualize/detection/detection.py
+-rw-r--r--  2.0 unx     4862 b- defN 23-Jul-12 11:51 data_gradients/visualize/detection/detection_legend.py
+-rw-r--r--  2.0 unx     1432 b- defN 23-Jul-12 11:51 data_gradients/visualize/detection/utils.py
+-rw-r--r--  2.0 unx    11341 b- defN 23-Jul-12 11:57 data_gradients-0.1.3.dist-info/LICENSE.md
+-rw-r--r--  2.0 unx    11608 b- defN 23-Jul-12 11:57 data_gradients-0.1.3.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-12 11:57 data_gradients-0.1.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx       15 b- defN 23-Jul-12 11:57 data_gradients-0.1.3.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    12527 b- defN 23-Jul-12 11:57 data_gradients-0.1.3.dist-info/RECORD
+119 files, 668404 bytes uncompressed, 395561 bytes compressed:  40.8%
```

## zipnote {}

```diff
@@ -336,23 +336,23 @@
 
 Filename: data_gradients/visualize/detection/detection_legend.py
 Comment: 
 
 Filename: data_gradients/visualize/detection/utils.py
 Comment: 
 
-Filename: data_gradients-0.1.2.dist-info/LICENSE.md
+Filename: data_gradients-0.1.3.dist-info/LICENSE.md
 Comment: 
 
-Filename: data_gradients-0.1.2.dist-info/METADATA
+Filename: data_gradients-0.1.3.dist-info/METADATA
 Comment: 
 
-Filename: data_gradients-0.1.2.dist-info/WHEEL
+Filename: data_gradients-0.1.3.dist-info/WHEEL
 Comment: 
 
-Filename: data_gradients-0.1.2.dist-info/top_level.txt
+Filename: data_gradients-0.1.3.dist-info/top_level.txt
 Comment: 
 
-Filename: data_gradients-0.1.2.dist-info/RECORD
+Filename: data_gradients-0.1.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## data_gradients/__init__.py

```diff
@@ -1 +1 @@
-__version__ = "0.1.2"
+__version__ = "0.1.3"
```

## data_gradients/assets/html/doc_template.html

```diff
@@ -319,9 +319,13 @@
                     {{feature.warning}}
                 </div>
                 {% endif %}
             {% endfor %}
         <p class="c0 c2"><span class="c1"></span></p>
         <p class="c0 c2"><span class="c1"></span></p>
     {% endfor %}
+    <div class="alert-box notice">
+        <span><img  src="{{assets.image.info}}" width="40pt" height="25pt">Notice: </span>
+        To better understand how to tackle the data issues highlighted in this report, explore our comprehensive <a href="https://deci.ai/course/profiling-computer-vision-datasets-overview/?utm_campaign[…]=DG-PDF-report&utm_medium=DG-repo&utm_content=DG-Report-to-course">course</a> on analyzing computer vision datasets.
+    </div>
 </body>
 </html>
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### html2text {}

```diff
@@ -12,7 +12,10 @@
  
 {% if feature.notice is not none %}
 [{{assets.image.info}}]Notice:  {{feature.notice}}
 {% endif %} {% if feature.warning is not none %}
 [{{assets.image.warning}}]Warning:  {{feature.warning}}
 {% endif %} {% endfor %}
 {% endfor %}
+[{{assets.image.info}}]Notice:  To better understand how to tackle the data
+issues highlighted in this report, explore our comprehensive course on
+analyzing computer vision datasets.
```

## data_gradients/batch_processors/formatters/segmentation.py

```diff
@@ -137,21 +137,23 @@
         :param labels:      Tensor [BS, W, H] or [BS, N, W, H]
         :return: labels:    Tensor [BS, N, W, H]
         """
         if labels.dim() == 3:
             return labels  # Assuming [BS, W, H]
         elif labels.dim() == 4:
             total_n_classes = n_classes + len(ignore_labels)
-            valid_n_classes = (total_n_classes, 1)
-            input_n_classes = labels.shape[1]
-            if input_n_classes not in valid_n_classes and labels.shape[-1] not in valid_n_classes:
-                raise DatasetFormatError(
-                    f"Labels batch shape should be [BS, N, W, H] where N is either 1 or n_classes + len(ignore_labels)"
-                    f" ({total_n_classes}). Got: {input_n_classes}"
-                )
+
+            # Check if first or last dim is 1; it can be due to mask being saved with [1, H, W] or [H, W, 1]
+            if labels.shape[1] == 1 and labels.shape[1] != total_n_classes:
+                return labels.squeeze(1)  # [BS, 1, W, H] -> [BS, W, H] (categorical representation)
+            elif labels.shape[-1] == 1 and labels.shape[-1] != total_n_classes:
+                return labels.squeeze(-1)  # [BS, W, H, 1] -> [BS, W, H] (categorical representation)
+            elif not (labels.shape[1] == total_n_classes or labels.shape[-1] == total_n_classes):
+                # We have 4 dims, but it's neither [BS, N, W, H] nor [BS, W, H, N]
+                raise DatasetFormatError(f"Labels batch shape should be [BS, N, W, H] where N is n_classes. Got {labels.shape}")
             return labels
         else:
             raise DatasetFormatError(f"Labels batch shape should be [Channels x Width x Height] or [BatchSize x Channels x Width x Height]. Got {labels.shape}")
 
     @staticmethod
     def binary_mask_above_threshold(labels: Tensor, threshold_value: float) -> Tensor:
         # Support only for binary segmentation
```

## data_gradients/config/data/questions.py

```diff
@@ -1,17 +1,11 @@
 from dataclasses import dataclass
 from typing import Dict, Any, Optional, List
 
-
-def text_to_blue(text: str) -> str:
-    return f"\033[34;1m{text}\033[0m"
-
-
-def text_to_yellow(text: str):
-    return f"\033[33;1m{text}\033[0m"
+from data_gradients.utils.utils import text_to_blue, text_to_yellow
 
 
 @dataclass
 class Question:
     """Model a Question with its options
     :attr question: The question string
     :attr options: The options for the question
```

## data_gradients/managers/abstract_manager.py

```diff
@@ -6,14 +6,15 @@
 from itertools import zip_longest
 from logging import getLogger
 from tqdm import tqdm
 
 from data_gradients.feature_extractors import AbstractFeatureExtractor
 from data_gradients.batch_processors.base import BatchProcessor
 from data_gradients.feature_extractors.common import SummaryStats
+from data_gradients.utils.utils import print_in_box
 from data_gradients.visualize.seaborn_renderer import SeabornRenderer
 from data_gradients.utils.pdf_writer import ResultsContainer, Section, FeatureSummary
 from data_gradients.utils.summary_writer import SummaryWriter
 from data_gradients.config.data.data_config import DataConfig
 
 
 logging.basicConfig(level=logging.INFO)
@@ -94,14 +95,17 @@
             f"  - len(train_data): {self.train_size} \n"
             f"  - len(val_data): {self.val_size} \n"
             f"  - log directory: {self.summary_writer.log_dir} \n"
             f"  - Archive directory: {self.summary_writer.archive_dir} \n"
             f"  - feature extractor list: {self.grouped_feature_extractors}"
         )
 
+        print_in_box("To better understand how to tackle the data issues highlighted in this report, explore our comprehensive course on analyzing "
+                     "computer vision datasets. click here: https://hubs.ly/Q01XpHBT0")
+
         datasets_tqdm = tqdm(
             zip_longest(self.train_iter, self.val_iter, fillvalue=None),
             desc="Analyzing... ",
             total=self.n_batches,
         )
 
         self._train_iters_done, self._val_iters_done = 0, 0
@@ -153,14 +157,15 @@
                     feature_error = ""
                 except Exception as e:
                     f = None
                     error_description = traceback.format_exception(type(e), e, e.__traceback__)
                     feature_json = {"error": error_description}
                     feature_error = f"Feature extraction error. Check out the log file for more details:<br/>" f"<em>{self.summary_writer.errors_path}</em>"
                     self.summary_writer.add_error(title=feature_extractor.title, error=error_description)
+                    logger.error(f"Feature extractor {feature_extractor} error: {error_description}")
 
                 if f is not None:
                     image_name = feature_extractor.__class__.__name__ + ".png"
                     image_path = os.path.join(self.summary_writer.archive_dir, image_name)
                     f.savefig(image_path, dpi=200)
                     images_created.append(image_path)
                 else:
@@ -261,8 +266,15 @@
         return msg_head + msg_train + msg_val
 
     @staticmethod
     def _format_feature_description(description: str) -> str:
         """
         Formats the feature extractor's description string for a vieable display in HTML.
         """
-        return description.replace("\n", "<br />")
+        if AnalysisManagerAbstract._is_html(description):
+            return description
+        else:
+            return description.replace("\n", "<br />")
+
+    @staticmethod
+    def _is_html(description: str) -> bool:
+        return description.startswith("<") and description.endswith(">")
```

## data_gradients/managers/detection_manager.py

```diff
@@ -29,15 +29,15 @@
         class_names_to_use: Optional[List[str]] = None,
         n_classes: Optional[int] = None,
         images_extractor: Optional[Callable[[SupportedDataType], torch.Tensor]] = None,
         labels_extractor: Optional[Callable[[SupportedDataType], torch.Tensor]] = None,
         is_label_first: Optional[bool] = None,
         bbox_format: Optional[str] = None,
         n_image_channels: int = 3,
-        batches_early_stop: int = 999,
+        batches_early_stop: Optional[int] = None,
         remove_plots_after_report: Optional[bool] = True,
     ):
         """
         Constructor of detection manager which controls the analyzer
         :param report_title:            Title of the report. Will be used to save the report
         :param report_subtitle:         Subtitle of the report
         :param class_names:             List of all class names in the dataset. The index should represent the class_id.
@@ -104,9 +104,9 @@
             report_subtitle=report_subtitle,
             train_data=train_data,
             val_data=val_data,
             batch_processor=batch_processor,
             grouped_feature_extractors=grouped_feature_extractors,
             log_dir=log_dir,
             batches_early_stop=batches_early_stop,
-            remove_plots_after_report=remove_plots_after_report
+            remove_plots_after_report=remove_plots_after_report,
         )
```

## data_gradients/managers/segmentation_manager.py

```diff
@@ -28,15 +28,15 @@
         class_names: Optional[List[str]] = None,
         class_names_to_use: Optional[List[str]] = None,
         n_classes: Optional[int] = None,
         images_extractor: Optional[Callable[[SupportedDataType], torch.Tensor]] = None,
         labels_extractor: Optional[Callable[[SupportedDataType], torch.Tensor]] = None,
         num_image_channels: int = 3,
         threshold_soft_labels: float = 0.5,
-        batches_early_stop: int = 999,
+        batches_early_stop: Optional[int] = None,
         remove_plots_after_report: Optional[bool] = True,
     ):
         """
         Constructor of semantic-segmentation manager which controls the analyzer
 
         :param report_title:            Title of the report. Will be used to save the report
         :param report_subtitle:         Subtitle of the report
```

## data_gradients/utils/utils.py

```diff
@@ -73,7 +73,60 @@
     if not os.path.exists(path):
         return {}
     try:
         with open(path, "r") as f:
             return json.load(f)
     except json.decoder.JSONDecodeError:
         return {}
+
+
+def text_to_blue(text: str) -> str:
+    return f"\033[34;1m{text}\033[0m"
+
+
+def text_to_yellow(text: str):
+    return f"\033[33;1m{text}\033[0m"
+
+
+def break_text(text: str, line_length: int):
+    lines = []
+    words = text.split()
+    current_line = []
+    current_length = 0
+
+    for word in words:
+        word_length = len(word)
+
+        if current_length + len(current_line) + word_length <= line_length:
+            current_line.append(word)
+            current_length += word_length
+        else:
+            lines.append(' '.join(current_line))
+            current_line = [word]
+            current_length = word_length
+
+    if current_line:
+        lines.append(' '.join(current_line))
+
+    # Add spaces to the end of each line to make them equal in length
+    for i in range(len(lines)):
+        spaces_needed = line_length - len(lines[i])
+        lines[i] += ' ' * spaces_needed
+
+    return lines
+
+
+def print_in_box(text_lines: str, box_size: int = 70):
+    left = text_to_blue("║  ")
+    right = text_to_blue("  ║")
+    bottom_left = text_to_blue("╚")
+    top_bottom = text_to_blue("═")
+    top_left = text_to_blue("╔")
+    top_right = text_to_blue("╗")
+    bottom_right = text_to_blue("╝")
+
+    lines = break_text(text_lines, box_size)
+    top_bottom = top_bottom * (box_size + 4)
+    print(top_left + top_bottom + top_right)
+    for text in lines:
+        print(left + text + right)
+    print(bottom_left + top_bottom +bottom_right)
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## Comparing `data_gradients-0.1.2.dist-info/LICENSE.md` & `data_gradients-0.1.3.dist-info/LICENSE.md`

 * *Files identical despite different names*

## Comparing `data_gradients-0.1.2.dist-info/METADATA` & `data_gradients-0.1.3.dist-info/METADATA`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: data-gradients
-Version: 0.1.2
+Version: 0.1.3
 Summary: DataGradients
 Home-page: https://github.com/Deci-AI/data-gradients
 Author: Deci AI
 Author-email: rnd@deci.ai
 Keywords: Deci,AI,Data,Deep Learning,Computer Vision,PyTorch
 Description-Content-Type: text/markdown
 License-File: LICENSE.md
@@ -58,34 +58,42 @@
 ## Features
 - Image-Level Evaluation: DataGradients evaluates key image features such as resolution, color distribution, and average brightness.
 - Class Distribution: The library extracts stats allowing you to know which classes are the most used, how many objects do you have per image, how many image without any label, ...
 - Heatmap Generation: DataGradients produces heatmaps of bounding boxes or masks, allowing you to understand if the objects are positioned in the right area.
 - And [many more](./documentation/feature_description.md)!
 
 <div align="center">
-  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_image_stats.png"><img src="documentation/assets/report_image_stats.png" width="250px"></a>
-  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_mask_sample.png"><img src="documentation/assets/report_mask_sample.png" width="250px"></a>
-  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_classes_distribution.png"><img src="documentation/assets/report_classes_distribution.png" width="250px"></a>
+  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_image_stats.png"><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_image_stats.png" width="250px"></a>
+  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_mask_sample.png"><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_mask_sample.png" width="250px"></a>
+  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_classes_distribution.png"><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/report_classes_distribution.png" width="250px"></a>
   <p><em>Example of pages from the Report</em>
 </div>
 
 <div align="center">
-  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationBoundingBoxArea.png"><img src="documentation/assets/SegmentationBoundingBoxArea.png" width="375px"></a>
-  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationBoundingBoxResolution.png"><img src="documentation/assets/SegmentationBoundingBoxResolution.png" width="375px"></a>
+  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationBoundingBoxArea.png"><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationBoundingBoxArea.png" width="375px"></a>
+  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationBoundingBoxResolution.png"><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationBoundingBoxResolution.png" width="375px"></a>
   <br />
-  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationClassFrequency.png"><img src="documentation/assets/SegmentationClassFrequency.png" width="375px"></a>
-  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationComponentsPerImageCount.png"><img src="documentation/assets/SegmentationComponentsPerImageCount.png" width="375px"></a>
+  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationClassFrequency.png"><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationClassFrequency.png" width="375px"></a>
+  <a href="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationComponentsPerImageCount.png"><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/SegmentationComponentsPerImageCount.png" width="375px"></a>
   <p><em>Example of specific features</em>
 </div>
 
 ## Examples 
 [COCO 2017 Detection report](documentation/assets/Report_COCO.pdf)
 
 [Cityscapes Segmentation report](documentation/assets/Report_CityScapes.pdf)
 
+<table style="border: 0">
+  <tr>
+    <td><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/colab.png" width="80pt"></td>
+    <td><a href="https://colab.research.google.com/drive/1dswgeK0KF-n61p6ixRdFgbQKHEtOu8SE?usp=sharing"> Example notebook on Colab</a></td>
+  </tr>
+</table>
+
+
 ## Installation
 You can install DataGradients directly from the GitHub repository.
 
 ```
 pip install data-gradients
 ```
 
@@ -266,11 +274,18 @@
 
 SegmentationAnalysisManager(
     ...,
     labels_extractor=labels_extractor
 )
 ```
 
+## Community
+<table style="border: 0">
+  <tr>
+    <td><img src="https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/discord.png" width="60pt"></td>
+    <td><a href="https://discord.gg/2v6cEGMREN"> Click here to join our Discord Community</a></td>
+  </tr>
+</table>
 
 ## License
 
 This project is released under the [Apache 2.0 license](LICENSE.md).
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: data-gradients Version: 0.1.2 Summary:
+Metadata-Version: 2.1 Name: data-gradients Version: 0.1.3 Summary:
 DataGradients Home-page: https://github.com/Deci-AI/data-gradients Author: Deci
 AI Author-email: rnd@deci.ai Keywords: Deci,AI,Data,Deep Learning,Computer
 Vision,PyTorch Description-Content-Type: text/markdown License-File: LICENSE.md
 Requires-Dist: hydra-core (>=1.2.0) Requires-Dist: omegaconf (>=2.2.3)
 Requires-Dist: pygments (>=2.13.0) Requires-Dist: tqdm (>=4.64.1) Requires-
 Dist: platformdirs (>=2.5.2) Requires-Dist: opencv-python Requires-Dist: Pillow
 Requires-Dist: tensorboard Requires-Dist: torch Requires-Dist: torchvision
@@ -26,28 +26,34 @@
 such as resolution, color distribution, and average brightness. - Class
 Distribution: The library extracts stats allowing you to know which classes are
 the most used, how many objects do you have per image, how many image without
 any label, ... - Heatmap Generation: DataGradients produces heatmaps of
 bounding boxes or masks, allowing you to understand if the objects are
 positioned in the right area. - And [many more](./documentation/
 feature_description.md)!
-     [documentation/assets/report_image_stats.png] [documentation/assets/
-report_mask_sample.png] [documentation/assets/report_classes_distribution.png]
+  [https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/
+report_image_stats.png] [https://github.com/Deci-AI/data-gradients/raw/master/
+documentation/assets/report_mask_sample.png] [https://github.com/Deci-AI/data-
+  gradients/raw/master/documentation/assets/report_classes_distribution.png]
                        Example of pages from the Report
- [documentation/assets/SegmentationBoundingBoxArea.png] [documentation/assets/
-                    SegmentationBoundingBoxResolution.png]
- [documentation/assets/SegmentationClassFrequency.png] [documentation/assets/
-                   SegmentationComponentsPerImageCount.png]
+  [https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/
+ SegmentationBoundingBoxArea.png] [https://github.com/Deci-AI/data-gradients/
+    raw/master/documentation/assets/SegmentationBoundingBoxResolution.png]
+  [https://github.com/Deci-AI/data-gradients/raw/master/documentation/assets/
+SegmentationClassFrequency.png] [https://github.com/Deci-AI/data-gradients/raw/
+     master/documentation/assets/SegmentationComponentsPerImageCount.png]
                          Example of specific features
 ## Examples [COCO 2017 Detection report](documentation/assets/Report_COCO.pdf)
-[Cityscapes Segmentation report](documentation/assets/Report_CityScapes.pdf) ##
-Installation You can install DataGradients directly from the GitHub repository.
-``` pip install data-gradients ``` ## Quick Start ### Prerequisites -
-**Dataset**: Includes a **Train** set and a **Validation** or a **Test** set. -
-**Class Names**: A list of the unique categories present in your dataset. -
+[Cityscapes Segmentation report](documentation/assets/Report_CityScapes.pdf)
+[https://github.com/Deci-AI/data-gradients/raw/ Example_notebook_on_Colab
+master/documentation/assets/colab.png]
+## Installation You can install DataGradients directly from the GitHub
+repository. ``` pip install data-gradients ``` ## Quick Start ### Prerequisites
+- **Dataset**: Includes a **Train** set and a **Validation** or a **Test** set.
+- **Class Names**: A list of the unique categories present in your dataset. -
 **Iterable**: A method to iterate over your Dataset providing images and
 labels. Can be any of the following: - PyTorch Dataloader - PyTorch Dataset -
 Generator that yields image/label pairs - Any other iterable you use for model
 training/validation Please ensure all the points above are checked before you
 proceed with **DataGradients**. **Good to Know**: DataGradients will try to
 find out how the dataset returns images and labels. - If something cannot be
 automatically determined, you will be asked to provide some extra information
@@ -115,9 +121,12 @@
 `annotation`, you will need to implement your own custom `labels_extractor` as
 below: ``` python from data_gradients.managers.segmentation_manager import
 SegmentationAnalysisManager def labels_extractor(data: Tuple[PIL.Image.Image,
 List[Dict]]) -> torch.Tensor: _image, annotations = data[:2] labels = [] for
 annotation in annotations: class_id = annotation["class_id"] bbox = annotation
 ["bbox_coordinates"] labels.append((class_id, *bbox)) return torch.Tensor
 (labels) SegmentationAnalysisManager( ..., labels_extractor=labels_extractor )
-``` ## License This project is released under the [Apache 2.0 license]
-(LICENSE.md).
+``` ## Community
+[https://github.com/Deci-AI/data-
+gradients/raw/master/documentation/ Click_here_to_join_our_Discord_Community
+assets/discord.png]
+## License This project is released under the [Apache 2.0 license](LICENSE.md).
```

## Comparing `data_gradients-0.1.2.dist-info/RECORD` & `data_gradients-0.1.3.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-data_gradients/__init__.py,sha256=YvuYzWnKtqBb-IqG8HAu-nhIYAsgj9Vmc_b9o7vO-js,22
+data_gradients/__init__.py,sha256=XEqb2aiIn8fzGE68Mph4ck1FtQqsR_am0wRWvrYPffQ,22
 data_gradients/requirements.txt,sha256=-vtVqLU6jHSCrMUQa80TPVRUa7DU7ERpob2CMpKo-6Q,221
 data_gradients/assets/__init__.py,sha256=u-dAbknZKaLTrSPCuSm7mOxVUTisTla2P9zlRp7a1nU,231
 data_gradients/assets/assets_container.py,sha256=nsY6AYtlG1TdfrF9atdYzGcqdzpqFByXG3UqV-4ODuY,2755
 data_gradients/assets/css/test.css,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 data_gradients/assets/html/basic_info_fe.html,sha256=NQEw0h3ww6gq20qK30vkJZ7O6okrV0X8R5X7IRupjyY,3244
-data_gradients/assets/html/doc_template.html,sha256=yYMAT9adkR-EP-zVIrhSxuWCyLWYDATpPleRqvQolks,8301
+data_gradients/assets/html/doc_template.html,sha256=dpRid2NrCJirU8cfC9UClkIKU07tqIclXM7iHwGkcQc,8762
 data_gradients/assets/html/test.html,sha256=WUoHLRvnM8pf46wEf7OcNsQyyubQfn1JiNt2t49YvJ4,123
 data_gradients/assets/images/chart_demo.png,sha256=zlOr7jOIHD-DTAQccBOgeJ9CNeMfaqF5gvr3o3Ui0OU,51292
 data_gradients/assets/images/info.png,sha256=fowx3nTT6ZVy4SuJecN13R_SXos3Uo2v9AbM73Mr9FE,139838
 data_gradients/assets/images/logo.png,sha256=EgIIuDIL3HHWDPk_2qPD7-sFB8s1ERXrTXZI5nLG4IM,36081
 data_gradients/assets/images/warning.png,sha256=XVnDsyHU2u0Hqg5FHMmrL5orUqWTbwFNyLLxGmfogZQ,75086
 data_gradients/assets/text/lorem_ipsum.txt,sha256=V22Sg3hEbEGrGrf4s0Up6lvSyZxcY0qhVFEGFeradQM,333
 data_gradients/assets/text/test.txt,sha256=dQnlvaDHYtK6x_kNdYtbImP6Acy8VCq1498WO-CObKk,12
@@ -19,15 +19,15 @@
 data_gradients/batch_processors/utils.py,sha256=C9S-TcrycZvWmnwrO-QKu0imouqHopfa0--ddx3yhUM,1155
 data_gradients/batch_processors/adapters/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 data_gradients/batch_processors/adapters/dataset_adapter.py,sha256=dlgINiDcyBoX7DGCkoyDDhhdbETUzXWWcDVOOf3ETTw,4621
 data_gradients/batch_processors/adapters/tensor_extractor.py,sha256=ri-WRtTGCF0C5Fczd4iLGYKOU3zdKyaMPyaBvrKczyg,6698
 data_gradients/batch_processors/formatters/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 data_gradients/batch_processors/formatters/base.py,sha256=4_NXp9XjU5M4LHACcEhvuOSGb4UhwrZAutJKwB3HJGE,725
 data_gradients/batch_processors/formatters/detection.py,sha256=kNTSpd5vckOtyO925-9D2z-QolOY4GNiHiKj8z2xXc0,9044
-data_gradients/batch_processors/formatters/segmentation.py,sha256=AulVeZEo5AViQpLU4tsCaCdKyptLqkDBBfq3xurgzNI,7181
+data_gradients/batch_processors/formatters/segmentation.py,sha256=aOBUOfDxu7JwFcLw3gXEiPZHvVm7v_PwbpXTZz3Aw10,7516
 data_gradients/batch_processors/formatters/utils.py,sha256=4Mez4LUbTOw8skJ1kKrvbh4_67whn28vtzdqK_ta3A8,1912
 data_gradients/batch_processors/preprocessors/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 data_gradients/batch_processors/preprocessors/base.py,sha256=6WUenirzUy7NpxrTAaN0sAxSld04_IncVSgeq6sffZU,994
 data_gradients/batch_processors/preprocessors/contours.py,sha256=s9-cHTXOSMyRaFogaeCK3OfX75DjGumpAeE10JHeUew,5189
 data_gradients/batch_processors/preprocessors/detection.py,sha256=dyqD90Z4sC7nJonpOKf2lIYNom_gEtLEBMIYS5q21eY,2527
 data_gradients/batch_processors/preprocessors/segmentation.py,sha256=4GtACw_1DHMILLUpTFR5InVysP5YBza-fKdW8Rap3sM,1836
 data_gradients/common/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -42,15 +42,15 @@
 data_gradients/config/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 data_gradients/config/detection.yaml,sha256=8byU7PluJwNGZPscs5UAj1Xp8V0l72-WeUChnuoewHM,903
 data_gradients/config/segmentation.yaml,sha256=ldKjTybVqSvRnXuFg3Lv6Ff10VYodg2G33a_X2MnQO0,954
 data_gradients/config/utils.py,sha256=KxIt36cZqP4fTE61h5Dp7U0KLK8dZtXARjgo1qK4rFo,6641
 data_gradients/config/data/__init__.py,sha256=v5G5etJhQHboiotmoFIdnex7_4cPdhPqlk4CXdSJij4,157
 data_gradients/config/data/caching_utils.py,sha256=JDvI-hEAr94_526nyM4dH__Tmmzryj2FbNiOTjoTja8,8725
 data_gradients/config/data/data_config.py,sha256=UigT15qaxmGyEHMkt3J1UJFS0ufqUzYGCjK__DX7juA,8676
-data_gradients/config/data/questions.py,sha256=db6e95Xsx_hdLtxf0qvOKUrxevHArSPoqXD6oScTP-0,2894
+data_gradients/config/data/questions.py,sha256=tuDvkdjGkFn6sXC_qguvhuBxubND4mY5YawlGkHYlXk,2816
 data_gradients/config/data/typing.py,sha256=vgfMZVxGsD7hqpAQl11Y_SeD5_sdy4A3T9JWNAFOAeQ,503
 data_gradients/datasets/FolderProcessor.py,sha256=8CrZDEKYxSqTwFIf6X93UBIyzFumJqDmxVSw-TITIuE,9524
 data_gradients/datasets/__init__.py,sha256=AkMyc4HAM0nx8ZW_sa_28euuvyEL4CYRsbRDvNsS-Iw,288
 data_gradients/datasets/base_dataset.py,sha256=PzwXmg_e693IwU25a7X9MGYWTUSCSaGQMD3DkvdpSyA,2820
 data_gradients/datasets/bdd_dataset.py,sha256=fWulH4IsYwhHCp9N0NtKLqSvAIhB7qknAoTs1cUrna0,2265
 data_gradients/datasets/utils.py,sha256=cbUB2jrtl3Mkk7IvG5nAoOv95uZ6ha3F-iRurPdGKrY,859
 data_gradients/datasets/detection/__init__.py,sha256=zX0VltL1bEsi23JvFauVRyjyQMxMVnaTqk4QUPQuOzs,386
@@ -85,35 +85,35 @@
 data_gradients/feature_extractors/segmentation/classes_frequency_per_image.py,sha256=6Z6estaGOm0CW8uEIvWcdkCcxlPH71eazaSWwhPcKLE,4251
 data_gradients/feature_extractors/segmentation/classes_heatmap_per_class.py,sha256=31iDn2VdG9hsgUx67OtJoibENjnXGuTahk98btCaqMM,2645
 data_gradients/feature_extractors/segmentation/component_frequency_per_image.py,sha256=lCHg4-NS0fG1Iw6hEPzC2Kp0NgcZuE5r4ZY4KWHqOps,2135
 data_gradients/feature_extractors/segmentation/components_convexity.py,sha256=m9Fwl6p7gvmJvajejO-jLwge3_1ixvruTbuyS7uknys,2302
 data_gradients/feature_extractors/segmentation/components_erosion.py,sha256=RgzuXWrr0mfaiPSbc4nI4zztpNTYvei8_8C6pj52Ovs,3807
 data_gradients/feature_extractors/segmentation/sample_visualization.py,sha256=MNLQ24QaW-s0Mb9FnCT2X3YVD3pnBgZRFnyNNU0uNoA,2674
 data_gradients/managers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-data_gradients/managers/abstract_manager.py,sha256=LE3i3ZwcyaseoTGEU0MK0M5f7d57IUcmTtz9EREwZHM,12234
-data_gradients/managers/detection_manager.py,sha256=ClAL6wdMbl13ThfKTooJiRQqyedNEPtCTILfGZEMbGs,6065
-data_gradients/managers/segmentation_manager.py,sha256=lBOf3rA008_kSl0VGGYvX-A9U9q5JVCInb9WF5D0ZlE,5951
+data_gradients/managers/abstract_manager.py,sha256=cAwwUeufq7BRNkPY4FOWQz77yVBLjUOW6YyKCGNB63E,12869
+data_gradients/managers/detection_manager.py,sha256=tYeCshxKCUt0IPIvz9ZKvnse5DxowFUj6wQA6o3j0nc,6077
+data_gradients/managers/segmentation_manager.py,sha256=rCXyOtjrxeFisdqIJDJfvtIbO1c7F1noJThwxQl6O9M,5962
 data_gradients/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 data_gradients/utils/detection.py,sha256=SDtVB-M5yXPidlcOyW_axlieIOwHkIE01UNTtnB4Sgs,2819
 data_gradients/utils/image_processing.py,sha256=5E2qUPoXYCFIuTgQ9IzewDeZ-Ay0u10pyQuHhaCg7Ko,1052
 data_gradients/utils/pdf_writer.py,sha256=hsL_tTCaK_3xY8YpcuG9PZhWIF9AID6IWrw-DCVSKHc,2550
 data_gradients/utils/summary_writer.py,sha256=EtlMOkaXoBLd2w9sXBeuXlNdez01e6lzcuNzlJ4-pSE,3705
-data_gradients/utils/utils.py,sha256=N5WSyuVBY2Sxm4CdEXF8OAPK0cR1-gWmhbctUr_3Wk0,2561
+data_gradients/utils/utils.py,sha256=RgShSfdDag1iKBT-4WqkUXlXymcwLZPdZDHGIszUsds,4024
 data_gradients/utils/common/__init__.py,sha256=UdVptbzrZj_KxShVC3KQbzM1zLTAPDuKk0dE6KmWUiE,169
 data_gradients/utils/data_classes/__init__.py,sha256=4zkOKnF1rycWi34SXthwkqWeI1CzjTfTAWJUnLmxvQE,249
 data_gradients/utils/data_classes/contour.py,sha256=kqrU1QLpV6smKGkeXk_-sfRYEq6sHkoHXx4i3TMYvTY,260
 data_gradients/utils/data_classes/data_samples.py,sha256=RGDy6tewoeSrYcFZg7nCXdwF1TI2FZ7ZN-9w9apRsDE,3088
 data_gradients/utils/data_classes/extractor_results.py,sha256=f_49UZoq9SfwV6XlqeVNuztLG_PIJbTW6WX3Wz9Bv2o,3975
 data_gradients/visualize/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 data_gradients/visualize/images.py,sha256=PtBdSj8tSMf5qBh05JhcFhNTh9qDXwu9nJ9tO8C9b0g,5101
 data_gradients/visualize/plot_options.py,sha256=wuEQ8lkbyjb3OWnUxf-KU8M8aQm7EP01p-tVcDjFTXs,11756
 data_gradients/visualize/seaborn_renderer.py,sha256=K7eD6T2geWhFKXq8KkzRWgMDX6s2bhHXDA7E1O5EniA,16753
 data_gradients/visualize/utils.py,sha256=J4jYcpZ8nKZZxG633GJOWvnXDL0BmCf2EoOp726Qsts,1165
 data_gradients/visualize/detection/__init__.py,sha256=gqN9L_Vwo5csejFyzl9p6ZxAeVlO-ZDgeCOthooarCs,96
 data_gradients/visualize/detection/detection.py,sha256=MQb-jnxAeP0wy8ookeb0Ad3l73Bpli4dUGNqgk4Awrc,4075
 data_gradients/visualize/detection/detection_legend.py,sha256=GaqfSEDOczx8xWfbSbhxFWCWZP_IG2id5nXZFb854bg,4862
 data_gradients/visualize/detection/utils.py,sha256=pI0IDThWVfVmxwQaYVk13OK_TYuSg-G_vbnZu9cKooo,1432
-data_gradients-0.1.2.dist-info/LICENSE.md,sha256=jWCBQN-JmCX0hwvn3MqItDj18W3riP4zda31ncMkcfA,11341
-data_gradients-0.1.2.dist-info/METADATA,sha256=kCr_sIa9ukLWAG1nvYj1EKFd0LiuhvaMjilSWnFbASw,10637
-data_gradients-0.1.2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-data_gradients-0.1.2.dist-info/top_level.txt,sha256=zATNcRYA5TY95dQFVVrFbhJndVZotUYDEM2v3kL_84E,15
-data_gradients-0.1.2.dist-info/RECORD,,
+data_gradients-0.1.3.dist-info/LICENSE.md,sha256=jWCBQN-JmCX0hwvn3MqItDj18W3riP4zda31ncMkcfA,11341
+data_gradients-0.1.3.dist-info/METADATA,sha256=lJFHDcWQ2NpfkoeceOyK_2qEw5p7n_zJ7nftaMClXPg,11608
+data_gradients-0.1.3.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+data_gradients-0.1.3.dist-info/top_level.txt,sha256=zATNcRYA5TY95dQFVVrFbhJndVZotUYDEM2v3kL_84E,15
+data_gradients-0.1.3.dist-info/RECORD,,
```

