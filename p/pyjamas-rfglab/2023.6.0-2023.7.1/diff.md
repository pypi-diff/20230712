# Comparing `tmp/pyjamas_rfglab-2023.6.0-py3-none-any.whl.zip` & `tmp/pyjamas_rfglab-2023.7.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,13 +1,13 @@
-Zip file size: 353554 bytes, number of entries: 81
+Zip file size: 351937 bytes, number of entries: 81
 -rw-r--r--  2.0 unx    33144 b- defN 20-Feb-04 05:51 pyjamas/LICENSE
 -rw-r--r--  2.0 unx     1088 b- defN 20-Jan-17 04:15 pyjamas/__init__.py
 -rw-r--r--  2.0 unx     1793 b- defN 21-Aug-22 22:40 pyjamas/dragdropmainwindow.py
 -rw-r--r--  2.0 unx     4901 b- defN 23-Jan-22 21:23 pyjamas/orthogonalviewswindow.py
--rw-r--r--  2.0 unx    52550 b- defN 23-Jun-09 18:33 pyjamas/pjscore.py
+-rw-r--r--  2.0 unx    52550 b- defN 23-Jul-11 19:12 pyjamas/pjscore.py
 -rw-r--r--  2.0 unx    32616 b- defN 23-Apr-12 16:40 pyjamas/pjseventfilter.py
 -rw-r--r--  2.0 unx     2123 b- defN 20-Feb-19 06:14 pyjamas/pjsthreads.py
 -rw-r--r--  2.0 unx  2950837 b- defN 23-Jun-21 15:47 pyjamas/pyjamas.tif
 -rw-r--r--  2.0 unx    26659 b- defN 22-Nov-12 20:45 pyjamas/rutils.py
 -rw-r--r--  2.0 unx     1645 b- defN 23-Apr-12 16:40 pyjamas/dialogs/__init__.py
 -rw-r--r--  2.0 unx    17513 b- defN 20-Jul-11 20:07 pyjamas/dialogs/adjustcontrast.py
 -rw-r--r--  2.0 unx    28797 b- defN 22-Oct-11 19:50 pyjamas/dialogs/batchanalysis.py
@@ -44,15 +44,15 @@
 -rw-r--r--  2.0 unx    52722 b- defN 23-Apr-24 20:27 pyjamas/rcallbacks/rcbio.py
 -rw-r--r--  2.0 unx    11288 b- defN 22-Dec-29 14:40 pyjamas/rcallbacks/rcbmeasure.py
 -rw-r--r--  2.0 unx    12556 b- defN 23-Mar-16 20:12 pyjamas/rcallbacks/rcboptions.py
 -rw-r--r--  2.0 unx     3617 b- defN 22-Aug-11 04:10 pyjamas/rcallbacks/rcbplugins.py
 -rw-r--r--  2.0 unx      913 b- defN 20-May-28 03:02 pyjamas/rimage/__init__.py
 -rw-r--r--  2.0 unx     3091 b- defN 21-Aug-22 22:13 pyjamas/rimage/csgraph.py
 -rw-r--r--  2.0 unx     3799 b- defN 23-Mar-14 22:07 pyjamas/rimage/rimcore.py
--rw-r--r--  2.0 unx    67122 b- defN 23-Jun-21 15:47 pyjamas/rimage/rimutils.py
+-rw-r--r--  2.0 unx    67108 b- defN 23-Jul-11 19:12 pyjamas/rimage/rimutils.py
 -rw-r--r--  2.0 unx     1484 b- defN 21-Feb-14 22:27 pyjamas/rimage/rimml/__init__.py
 -rw-r--r--  2.0 unx     3557 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/batchclassifier.py
 -rw-r--r--  2.0 unx     1585 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/batchml.py
 -rw-r--r--  2.0 unx     2740 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/batchneuralnet.py
 -rw-r--r--  2.0 unx     7409 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/batchrecurrentneuralnet.py
 -rw-r--r--  2.0 unx      275 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/classifier_types.py
 -rw-r--r--  2.0 unx     1173 b- defN 20-Aug-28 21:52 pyjamas/rimage/rimml/featurecalculator.py
@@ -60,24 +60,24 @@
 -rw-r--r--  2.0 unx     1289 b- defN 20-Dec-27 23:49 pyjamas/rimage/rimml/featurecalculator_rowofpixels.py
 -rw-r--r--  2.0 unx     3196 b- defN 21-Oct-27 19:58 pyjamas/rimage/rimml/featurecalculator_sog.py
 -rw-r--r--  2.0 unx    17339 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/rimclassifier.py
 -rw-r--r--  2.0 unx     1824 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/rimlr.py
 -rw-r--r--  2.0 unx     1382 b- defN 21-Oct-27 20:01 pyjamas/rimage/rimml/rimml.py
 -rw-r--r--  2.0 unx     1857 b- defN 21-Oct-27 20:01 pyjamas/rimage/rimml/rimneuralnet.py
 -rw-r--r--  2.0 unx     1960 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/rimrecurrentneuralnet.py
--rw-r--r--  2.0 unx    20936 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/rimrescunet.py
+-rw-r--r--  2.0 unx    20979 b- defN 23-Jul-11 19:12 pyjamas/rimage/rimml/rimrescunet.py
 -rw-r--r--  2.0 unx     2084 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/rimsvm.py
--rw-r--r--  2.0 unx    15137 b- defN 23-Apr-12 16:40 pyjamas/rimage/rimml/rimunet.py
+-rw-r--r--  2.0 unx    15508 b- defN 23-Jul-11 19:12 pyjamas/rimage/rimml/rimunet.py
 -rw-r--r--  2.0 unx      847 b- defN 20-Jan-17 04:15 pyjamas/rplugins/__init__.py
 -rw-r--r--  2.0 unx     1249 b- defN 23-Feb-19 02:47 pyjamas/rplugins/base.py
 -rw-r--r--  2.0 unx      796 b- defN 23-Jan-02 00:28 pyjamas/tests/__init__.py
 -rw-r--r--  2.0 unx      857 b- defN 23-Jan-19 20:27 pyjamas/tests/conftest.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Dec-25 02:03 pyjamas/tests/unit/__init__.py
--rw-r--r--  2.0 unx     5952 b- defN 23-Jun-20 21:53 pyjamas/tests/unit/pjsfixtures.py
--rw-r--r--  2.0 unx    11306 b- defN 23-Jun-21 16:46 pyjamas/tests/unit/test_image.py
--rw-r--r--  2.0 unx    17400 b- defN 23-Jun-21 16:46 pyjamas/tests/unit/test_io.py
--rw-r--r--  2.0 unx     8308 b- defN 23-Jun-21 21:33 pyjamas_rfglab-2023.6.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-21 21:33 pyjamas_rfglab-2023.6.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       50 b- defN 23-Jun-21 21:33 pyjamas_rfglab-2023.6.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        8 b- defN 23-Jun-21 21:33 pyjamas_rfglab-2023.6.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     7179 b- defN 23-Jun-21 21:33 pyjamas_rfglab-2023.6.0.dist-info/RECORD
-81 files, 3843491 bytes uncompressed, 342164 bytes compressed:  91.1%
+-rw-r--r--  2.0 unx     6326 b- defN 23-Jul-11 19:12 pyjamas/tests/unit/pjsfixtures.py
+-rw-r--r--  2.0 unx    12486 b- defN 23-Jul-11 19:12 pyjamas/tests/unit/test_image.py
+-rw-r--r--  2.0 unx    16795 b- defN 23-Jul-11 19:12 pyjamas/tests/unit/test_io.py
+-rw-r--r--  2.0 unx     2312 b- defN 23-Jul-12 16:44 pyjamas_rfglab-2023.7.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-12 16:44 pyjamas_rfglab-2023.7.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       49 b- defN 23-Jul-12 16:44 pyjamas_rfglab-2023.7.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        8 b- defN 23-Jul-12 16:44 pyjamas_rfglab-2023.7.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     7179 b- defN 23-Jul-12 16:44 pyjamas_rfglab-2023.7.1.dist-info/RECORD
+81 files, 3838843 bytes uncompressed, 340547 bytes compressed:  91.1%
```

## zipnote {}

```diff
@@ -222,23 +222,23 @@
 
 Filename: pyjamas/tests/unit/test_image.py
 Comment: 
 
 Filename: pyjamas/tests/unit/test_io.py
 Comment: 
 
-Filename: pyjamas_rfglab-2023.6.0.dist-info/METADATA
+Filename: pyjamas_rfglab-2023.7.1.dist-info/METADATA
 Comment: 
 
-Filename: pyjamas_rfglab-2023.6.0.dist-info/WHEEL
+Filename: pyjamas_rfglab-2023.7.1.dist-info/WHEEL
 Comment: 
 
-Filename: pyjamas_rfglab-2023.6.0.dist-info/entry_points.txt
+Filename: pyjamas_rfglab-2023.7.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: pyjamas_rfglab-2023.6.0.dist-info/top_level.txt
+Filename: pyjamas_rfglab-2023.7.1.dist-info/top_level.txt
 Comment: 
 
-Filename: pyjamas_rfglab-2023.6.0.dist-info/RECORD
+Filename: pyjamas_rfglab-2023.7.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pyjamas/pjscore.py

```diff
@@ -125,15 +125,15 @@
     livewire_margin: int = 5
     livewire_heuristic_weight: float = 0.  # defaults to Dijkstra.
     balloon_crop_size: int = 50  # crop size used to inflate balloons
 
     undo_stack_size: int = 500
 
     # Read version.
-    __version__: str = '2023.6.0'
+    __version__: str = '2023.7.1'
 
     def __init__(self):
         self.initData()  # Initialize object variables.
         self.setupUI()  # Build the GUI.
 
     def setupUI(self):
         self.app = QtWidgets.QApplication(sys.argv)
```

## pyjamas/rimage/rimutils.py

```diff
@@ -526,15 +526,15 @@
         :param gradient_flag: use the gradient magnitude or the pixel values for the cross-correlation calculations.
         :param border_width: how many rows and columns to remove (numpy.int).
         :param calculated_step_sz: distance between points in the source image where the cross-correlation will be
         calculated [row, col] (numpy.ndarray).
         :param filter_output: find and delete vectors too different from their neighbours (bool).
         :param min_normxcorr: minimum acceptable cross-correlation value (numpy.double).
         :rtype: (numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)
-        :return: (Xvaldesired, Yvaldesired, X0desired, Y0desired)
+        :return: (Xvaldesired, Yvaldesired, Xf, Yf)
         Xvaldesired: X end of the flow field vectors (numpy.ndarray).
         Yvaldesired: Y end of the flow field vectors (numpy.ndarray).
         Xf: X coordinates where the flow field was calculated (numpy.ndarray).
         Yf: Y coordinates where the flow field was calculated (numpy.ndarray).
         """
 
         if isinstance(window_sz, numbers.Number):
```

## pyjamas/rimage/rimml/rimrescunet.py

```diff
@@ -15,15 +15,14 @@
     You should have received a copy of the GNU General Public License
     along with this program.  If not, see <https://www.gnu.org/licenses/>.
 """
 
 import os
 from typing import Optional, Tuple
 
-import matplotlib.pyplot as plt
 import skimage.io as sio
 import skimage.morphology as sm
 import skimage.segmentation as ss
 import skimage.transform as st
 
 import tensorflow as tf
 import tensorflow.keras.backend as kb
@@ -38,15 +37,15 @@
 from pyjamas.rimage.rimutils import rimutils
 from pyjamas.rimage.rimml.rimrecurrentneuralnet import rimrecurrentneuralnet
 from pyjamas.rutils import RUtils
 
 
 class ReSCUNet(rimrecurrentneuralnet):
 
-    EROSION_WIDTH: int = 7
+    EROSION_WIDTH: int = 0
     CLASSIFIER_TYPE: str = classifier_types.RESCUNET.value
     CONCATENATION_LEVEL: int = 0
     VALIDATION_SPLIT: float = 0.1
 
     def __init__(self, parameters: Optional[dict] = None):
         super().__init__(parameters)
 
@@ -59,15 +58,15 @@
 
         self.epochs: int = parameters.get('epochs', ReSCUNet.EPOCHS)
         self.mini_batch_size: int = parameters.get('mini_batch_size', ReSCUNet.BATCH_SIZE)
 
         self.save_folder: str = parameters.get('save_folder')
         self.resize_images_flag: bool = parameters.get('resize_images_flag')
         self.train_network_flag: bool = parameters.get('train_network_flag')
-        self.EROSION_WIDTH: int = parameters.get('erosion_width')
+        self.EROSION_WIDTH: int = parameters.get('erosion_width', self.EROSION_WIDTH)
         self.CONCATENATION_LEVEL: int = parameters.get('concatenation_level')
 
         classifier_representation = parameters.get('classifier')
         if type(classifier_representation) is km.Model:
             self.classifier = classifier_representation
         else:
             if len(input_size) == 2:
@@ -307,45 +306,45 @@
         :return:
         """
         train_ids = next(os.walk(self.positive_training_folder))[1]
 
         # Get and resize train images and masks
         self.X_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.uint16)
         self.X_train_mask = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1),
-                                        dtype=numpy.bool)
-        self.Y_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.bool)
-        self.W_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.float)
+                                        dtype=bool)
+        self.Y_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=bool)
+        self.W_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=float)
         print('Getting and resizing train images and masks ... ')
 
         for n, id_ in enumerate(train_ids):
             print(f"Image number: {n}/{len(train_ids)}")
             path = self.positive_training_folder + id_
             im_file = path + "/image/" + os.listdir(path + "/image/")[0]
             img = sio.imread(im_file)
             if img.ndim == 3:
                 img = img[0, :, :]
             img = numpy.expand_dims(st.resize(img, (self.train_image_size[0], self.train_image_size[1]), order=3,
                                               mode='constant', preserve_range=True), axis=-1)
             self.X_train[n] = img
 
             prev_mask_file = path + "/prev_mask/" + os.listdir(path + "/prev_mask/")[0]
-            prev_mask = numpy.zeros((self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.bool)
+            prev_mask = numpy.zeros((self.train_image_size[0], self.train_image_size[1], 1), dtype=bool)
             prev_mask_ = sio.imread(prev_mask_file)
             prev_mask_ = numpy.expand_dims(st.resize(prev_mask_, (self.train_image_size[0], self.train_image_size[1]), order=3,
                                                      mode='constant', preserve_range=True), axis=-1)
             # Resizing interpolates values that makes the mask not binary, fix this by dividing by the max value,
             # rounding, and then multiplying again by the max value
             max_value = numpy.max(numpy.max(prev_mask_))
             prev_mask_ = numpy.round(numpy.divide(prev_mask_, numpy.full(prev_mask_.shape, max_value)))
             prev_mask_ = numpy.multiply(prev_mask_, numpy.full(prev_mask_.shape, max_value))
             prev_mask = numpy.maximum(prev_mask, prev_mask_)
             self.X_train_mask[n] = prev_mask
 
             msk_file = path + "/mask/" + os.listdir(path + "/mask/")[0]
-            mask = numpy.zeros((self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.bool)
+            mask = numpy.zeros((self.train_image_size[0], self.train_image_size[1], 1), dtype=bool)
             mask_ = sio.imread(msk_file)
             mask_ = numpy.expand_dims(st.resize(mask_, (self.train_image_size[0], self.train_image_size[1]), order=3,
                                                 mode='constant', preserve_range=True), axis=-1)
 
             # Resizing interpolates values that makes the mask not binary, fix this by dividing by the max value,
             # rounding, and then multiplying again by the max value
             max_value = numpy.max(numpy.max(mask_))
@@ -375,16 +374,16 @@
         testImage = image / self.scaler
 
         image_input = self.classifier.get_layer('image_input').input
         prev_mask_input = self.classifier.get_layer('mask_input').input
         softmax_output = self.classifier.get_layer('unet-activation').output
         predictor = kb.function([image_input, prev_mask_input], [softmax_output])
 
-        testLabel = numpy.zeros(testImage.shape, dtype=numpy.bool)
-        testProb = numpy.zeros(testImage.shape, dtype=numpy.bool)
+        testLabel = numpy.zeros(testImage.shape, dtype=bool)
+        testProb = numpy.zeros(testImage.shape, dtype=bool)
         half_width = int(self.train_image_size[1] / 2)
         half_height = int(self.train_image_size[0] / 2)
         for animage, therow, thecol in rimutils.generate_subimages(testImage, self.train_image_size[0:2],
                                                                    self.step_sz, True):
 
             prev_mask_subimage = prev_mask[(therow - half_height):(therow + half_height),
                                            (thecol - half_width):(thecol + half_width)]
@@ -393,20 +392,21 @@
             p = numpy.amax(yhat[0], axis=-1)
 
             testLabel[(therow - half_height):(therow + half_height), (thecol - half_width):(thecol + half_width)] \
                 = numpy.logical_or(testLabel[(therow - half_height):(therow + half_height),
                                    (thecol - half_width):(thecol + half_width)], yhat)
             testProb[(therow - half_height):(therow + half_height), (thecol - half_width):(thecol + half_width)] = p
 
-        if self.EROSION_WIDTH != 0:
+        if self.EROSION_WIDTH is not None and self.EROSION_WIDTH != 0:
             self.object_array = numpy.asarray(rimutils.extract_contours(
                 sm.dilation(sm.label(sm.binary_erosion(testLabel, sm.square(self.EROSION_WIDTH)), connectivity=1),
                             sm.square(self.EROSION_WIDTH))), dtype=object)
         else:
-            self.object_array = numpy.asarray(rimutils.extract_contours(sm.label(testLabel)), dtype=object)
+            self.object_array = numpy.asarray(rimutils.extract_contours(sm.label(testLabel, connectivity=1)),
+                                              dtype=object)
         self.prob_array = testProb
 
         return self.object_array.copy(), self.prob_array.copy()
 
     def save(self, filename: str) -> bool:
         classifier = self.classifier.get_weights() if self.classifier.weights else self.classifier
```

## pyjamas/rimage/rimml/rimunet.py

```diff
@@ -37,15 +37,15 @@
 from pyjamas.rimage.rimml.rimneuralnet import rimneuralnet
 from pyjamas.rutils import RUtils
 from pyjamas.rimage.rimml.classifier_types import classifier_types
 
 
 class UNet(rimneuralnet):
 
-    EROSION_WIDTH: int = 7
+    EROSION_WIDTH: int = 0
     CLASSIFIER_TYPE: str = classifier_types.UNET.value
     VALIDATION_SPLIT: float = 0.1
 
     def __init__(self, parameters: Optional[dict] = None):
         super().__init__(parameters)
 
         self.W_train: numpy.ndarray = None
@@ -53,14 +53,15 @@
         output_classes: int = parameters.get('output_classes', UNet.OUTPUT_CLASSES)
         learning_rate: float = parameters.get('learning_rate', UNet.LEARNING_RATE)
 
         input_size: Tuple[int, int, int] = parameters.get('train_image_size', UNet.TRAIN_IMAGE_SIZE)
 
         self.epochs: int = parameters.get('epochs', UNet.EPOCHS)
         self.mini_batch_size: int = parameters.get('mini_batch_size', UNet.BATCH_SIZE)
+        self.EROSION_WIDTH: int = parameters.get('erosion_width', self.EROSION_WIDTH)
 
         classifier_representation = parameters.get('classifier')
         if type(classifier_representation) is km.Model:
             self.classifier = classifier_representation
         else:
             if len(input_size) == 2:
                 input_size = input_size + (1, )
@@ -234,29 +235,29 @@
         Loads and scales training data and calculates weight maps.
         :return:
         """
         train_ids = next(os.walk(self.positive_training_folder))[1]
 
         # Get and resize train images and masks
         self.X_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.uint16)
-        self.Y_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.bool)
-        self.W_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.float)
+        self.Y_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=bool)
+        self.W_train = numpy.zeros((len(train_ids), self.train_image_size[0], self.train_image_size[1], 1), dtype=float)
         print('Getting and resizing train images and masks ... ')
 
         for n, id_ in enumerate(train_ids):
             path = self.positive_training_folder + id_
             im_file = path + "/image/" + os.listdir(path + "/image/")[0]
             img = sio.imread(im_file)
             if img.ndim == 3:
                 img = img[0, :, :]
             img = numpy.expand_dims(st.resize(img, (self.train_image_size[0], self.train_image_size[1]), order=3,
                                               mode='constant', preserve_range=True), axis=-1)
             self.X_train[n] = img
             msk_file = path + "/mask/" + os.listdir(path + "/mask/")[0]
-            mask = numpy.zeros((self.train_image_size[0], self.train_image_size[1], 1), dtype=numpy.bool)
+            mask = numpy.zeros((self.train_image_size[0], self.train_image_size[1], 1), dtype=bool)
             mask_ = sio.imread(msk_file)
             mask_ = numpy.expand_dims(st.resize(mask_, (self.train_image_size[0], self.train_image_size[1]), order=3,
                                                 mode='constant', preserve_range=True), axis=-1)
             mask = numpy.maximum(mask, mask_)
             weights = UNet.weight_map(mask)
             self.Y_train[n] = mask
             self.W_train[n, :, :, 0] = weights
@@ -275,16 +276,16 @@
 
         testImage = image / self.scaler
 
         image_input = self.classifier.get_layer('image_input').input
         softmax_output = self.classifier.get_layer('unet-activation').output
         predictor = kb.function([image_input], [softmax_output])
 
-        testLabel = numpy.zeros(testImage.shape, dtype=numpy.bool)
-        testProb = numpy.zeros(testImage.shape, dtype=numpy.bool)
+        testLabel = numpy.zeros(testImage.shape, dtype=bool)
+        testProb = numpy.zeros(testImage.shape, dtype=bool)
         half_width = int(self.train_image_size[1] / 2)
         half_height = int(self.train_image_size[0] / 2)
 
         for animage, therow, thecol in rimutils.generate_subimages(testImage, self.train_image_size[0:2],
                                                                    self.step_sz, True):
             yhat = predictor([numpy.expand_dims(animage, axis=0)])[0]
             yhat = numpy.argmax(yhat[0], axis=-1)
@@ -293,17 +294,21 @@
             testLabel[(therow - half_height):(therow + half_height),
             (thecol - half_width):(thecol + half_width)] = numpy.logical_or(
                 testLabel[(therow - half_height):(therow + half_height), (thecol - half_width):(thecol + half_width)],
                 yhat)
             testProb[(therow - half_height):(therow + half_height),
             (thecol - half_width):(thecol + half_width)] = p  # This is not really correct: one should select the probability that makes the pixel get its final value (or an average of those).
 
-        self.object_array = numpy.asarray(rimutils.extract_contours(
-            sm.dilation(sm.label(sm.binary_erosion(testLabel, sm.square(self.EROSION_WIDTH)), connectivity=1),
-                        sm.square(self.EROSION_WIDTH))), dtype=object)
+        if self.EROSION_WIDTH is not None and self.EROSION_WIDTH != 0:
+            self.object_array = numpy.asarray(rimutils.extract_contours(
+                sm.dilation(sm.label(sm.binary_erosion(testLabel, sm.square(self.EROSION_WIDTH)), connectivity=1),
+                            sm.square(self.EROSION_WIDTH))), dtype=object)
+        else:
+            self.object_array = numpy.asarray(rimutils.extract_contours(sm.label(testLabel, connectivity=1)),
+                                              dtype=object)
         self.prob_array = testProb
 
         return self.object_array.copy(), self.prob_array.copy()
 
     def save(self, filename: str) -> bool:
         classifier = self.classifier.get_weights() if self.classifier.weights else self.classifier
 
@@ -313,10 +318,11 @@
             'train_image_size': self.train_image_size,
             'scaler': self.scaler,
             'epochs': self.epochs,
             'mini_batch_size': self.mini_batch_size,
             'learning_rate': kb.eval(self.classifier.optimizer.lr),
             'classifier': self.classifier.get_weights(),
             'step_sz': self.step_sz,
+            'erosion_width': self.EROSION_WIDTH
         }
 
         return RUtils.pickle_this(theclassifier, RUtils.set_extension(filename, pyjamas.pjscore.PyJAMAS.classifier_extension))
```

## pyjamas/tests/unit/pjsfixtures.py

```diff
@@ -44,14 +44,15 @@
 FINDSEEDS_WINDOWSIZE: int = 16
 FINDSEEDS_MINDIST: float = 3.0
 FINDSEEDS_BINCLOSINGS: int = 2
 FINDSEEDS_ANNOTATIONSPATH: str = 'fiducials_sigma2_window16_closings2_mindist3.pjs'
 PROPAGATESEEDS_ANNOTATIONSPATH: str = 'propagatedfiducials_sigma2_window16_closings2_mindist3.pjs'
 PROPAGATESEEDS0_ANNOTATIONSPATH: str = 'propagatedfiducials0_sigma2_window16_closings2_mindist3.pjs'
 EXPANDSEEDS_ANNOTATIONSPATH: str = 'expandedfiducials_sigma2_window16_closings2_mindist3.pjs'
+EXPANDNPROPAGATESEEDS_ANNOTATIONSPATH: str = 'expandedpropagatedfiducials_sigma2_window16_closings2_mindist3.pjs'
 
 
 @pytest.fixture
 def image_fixture():
     return skimage.io.imread(os.path.join(FIXTURE_DIR, IMAGE_FIXTURE))
 
 
@@ -210,7 +211,17 @@
 def expandseedsannotationspath_fixture():
     return os.path.join(FIXTURE_DIR, EXPANDSEEDS_ANNOTATIONSPATH)
 
 
 @pytest.fixture
 def expandseeds_parameters():
     return 1, 1, FINDSEEDS_SIGMA
+
+
+@pytest.fixture
+def expandnpropagateseedsannotationspath_fixture():
+    return os.path.join(FIXTURE_DIR, EXPANDNPROPAGATESEEDS_ANNOTATIONSPATH)
+
+
+@pytest.fixture
+def expandnpropagateseeds_parameters():
+    return 1, 20, FINDSEEDS_SIGMA, FINDSEEDS_WINDOWSIZE
```

## pyjamas/tests/unit/test_image.py

```diff
@@ -267,15 +267,35 @@
     PyJAMAS_FIXTURE.io.cbLoadAnnotations([propagateseeds0annotationspath_fixture])
     PyJAMAS_FIXTURE.image.cbExpandSeeds(expandseeds_parameters[0], expandseeds_parameters[1], expandseeds_parameters[2],
                                         wait_for_thread=True)
 
     polylines = PyJAMAS_FIXTURE.polylines.copy()
     PyJAMAS_FIXTURE.io.cbLoadAnnotations([expandseedsannotationspath_fixture])
 
-    assert numpy.array_equal(polylines, PyJAMAS_FIXTURE.polylines)
+    assert polylines == PyJAMAS_FIXTURE.polylines
+
+
+@pytest.mark.usefixtures("imagepath_fixture")
+@pytest.mark.usefixtures("propagateseeds0annotationspath_fixture")
+@pytest.mark.usefixtures("expandnpropagateseeds_parameters")
+@pytest.mark.usefixtures("expandnpropagateseedsannotationspath_fixture")
+def test_cbExpandNPropagateSeeds(imagepath_fixture, propagateseeds0annotationspath_fixture, expandnpropagateseeds_parameters,
+                       expandnpropagateseedsannotationspath_fixture):
+    PyJAMAS_FIXTURE.io.cbLoadTimeSeries(imagepath_fixture)
+    PyJAMAS_FIXTURE.io.cbLoadAnnotations([propagateseeds0annotationspath_fixture])
+    PyJAMAS_FIXTURE.image.cbExpandNPropagateSeeds(expandnpropagateseeds_parameters[0],
+                                                  expandnpropagateseeds_parameters[1],
+                                                  expandnpropagateseeds_parameters[2],
+                                                  expandnpropagateseeds_parameters[3],
+                                                  wait_for_thread=True)
+
+    polylines = PyJAMAS_FIXTURE.polylines.copy()
+    PyJAMAS_FIXTURE.io.cbLoadAnnotations([expandnpropagateseedsannotationspath_fixture])
+
+    assert polylines == PyJAMAS_FIXTURE.polylines
 
 
 def test_cbDisplayInfo():
     assert PyJAMAS_FIXTURE.image.cbDisplayInfo()
 
 
 PyJAMAS_FIXTURE.app.quit()
```

## pyjamas/tests/unit/test_io.py

```diff
@@ -182,18 +182,16 @@
             gzip.open(os.path.join(pjsfixtures.TMP_DIR, pjsfixtures.TMP_SINGLE_CELL_PJS_FILE), "rb") as ffix:
         fiducials_exp = pickle.load(fexp)
         polylines_exp = pickle.load(fexp)
 
         fiducials_fix = pickle.load(ffix)
         polylines_fix = pickle.load(ffix)
 
-        assert numpy.array_equal(fiducials_exp, fiducials_fix) and \
-               numpy.array_equal(
-                   numpy.asarray([RUtils.qpolygonf2list(apolyline) for apolyline in polylines_exp]),
-                   numpy.asarray([RUtils.qpolygonf2list(apolyline) for apolyline in polylines_fix]))
+        assert fiducials_exp == fiducials_fix and \
+               polylines_exp == polylines_fix
 
 
 @pytest.mark.usefixtures("image_fixture")
 @pytest.mark.usefixtures("pjsannotationspath_fixture")
 @pytest.mark.usefixtures("singlecellpjsannotationspath_fixture")
 def test_cbExportAllPolylineAnnotations(image_fixture, pjsannotationspath_fixture,
                                         singlecellpjsannotationspath_fixture):
@@ -206,18 +204,16 @@
 
     PyJAMAS_FIXTURE.io.cbLoadAnnotations([os.path.join(pjsfixtures.TMP_DIR, pjsfixtures.TMP_SINGLE_CELL_PJS_FILE)])
 
     with gzip.open(singlecellpjsannotationspath_fixture, "rb") as fh:
         fiducials = pickle.load(fh)
         polylines = pickle.load(fh)
 
-    assert numpy.array_equal(fiducials, PyJAMAS_FIXTURE.fiducials) and \
-           numpy.array_equal(
-               numpy.asarray([RUtils.qpolygonf2list(apolyline) for apolyline in polylines]),
-               numpy.asarray([RUtils.qpolygonf2list(apolyline) for apolyline in PyJAMAS_FIXTURE.polylines]))
+    assert fiducials == PyJAMAS_FIXTURE.fiducials and \
+           polylines == RUtils.qpolygonfs2coordinatelists(PyJAMAS_FIXTURE.polylines)
 
 
 @pytest.mark.usefixtures("matannotationspath_fixture")
 @pytest.mark.usefixtures("imagepath_fixture")
 @pytest.mark.usefixtures("pjsannotationspath_fixture")
 def test_cbImportSIESTAAnnotations(matannotationspath_fixture, imagepath_fixture, pjsannotationspath_fixture):
     PyJAMAS_FIXTURE.io.cbLoadTimeSeries(imagepath_fixture)
@@ -225,35 +221,32 @@
 
     fiducials = PyJAMAS_FIXTURE.fiducials.copy()
     polylines = PyJAMAS_FIXTURE.polylines.copy()
 
     PyJAMAS_FIXTURE.io.cbLoadTimeSeries(imagepath_fixture)
     PyJAMAS_FIXTURE.io.cbImportSIESTAAnnotations([matannotationspath_fixture])
 
-    assert numpy.array_equal(fiducials, PyJAMAS_FIXTURE.fiducials) and \
-           numpy.array_equal(polylines, PyJAMAS_FIXTURE.polylines)
+    assert fiducials == PyJAMAS_FIXTURE.fiducials and \
+           polylines == PyJAMAS_FIXTURE.polylines
 
 
 @pytest.mark.usefixtures("image_fixture")
 @pytest.mark.usefixtures("pjsannotationspath_fixture")
 def test_cbExportSIESTAAnnotations(image_fixture, pjsannotationspath_fixture):
     PyJAMAS_FIXTURE.io.cbLoadArray(image_fixture)
     PyJAMAS_FIXTURE.io.cbLoadAnnotations([pjsannotationspath_fixture])
 
     fiducials = PyJAMAS_FIXTURE.fiducials.copy()
     polylines = PyJAMAS_FIXTURE.polylines.copy()
 
     PyJAMAS_FIXTURE.io.cbExportSIESTAAnnotations(os.path.join(pjsfixtures.TMP_DIR, pjsfixtures.TMP_PJS_FILE))
     PyJAMAS_FIXTURE.io.cbImportSIESTAAnnotations([os.path.join(pjsfixtures.TMP_DIR, pjsfixtures.TMP_PJS_FILE)])
 
-    assert numpy.array_equal(fiducials, PyJAMAS_FIXTURE.fiducials) and \
-           numpy.array_equal(
-               numpy.asarray([RUtils.qpolygonf2list(apolyline) for apolyline in polylines]),
-               numpy.asarray([RUtils.qpolygonf2list(apolyline) for apolyline in PyJAMAS_FIXTURE.polylines]))
-
+    assert fiducials == PyJAMAS_FIXTURE.fiducials and \
+           polylines == PyJAMAS_FIXTURE.polylines
 
 @pytest.mark.usefixtures("image_fixture")
 @pytest.mark.usefixtures("pjsannotationspath_fixture")
 def test_cbLoadAnnotations_additive(image_fixture, pjsannotationspath_fixture):
     PyJAMAS_FIXTURE.io.cbLoadArray(image_fixture)
     PyJAMAS_FIXTURE.io.cbLoadAnnotations([pjsannotationspath_fixture])
```

## Comparing `pyjamas_rfglab-2023.6.0.dist-info/RECORD` & `pyjamas_rfglab-2023.7.1.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 pyjamas/LICENSE,sha256=5lnHvn0CrsS-hm-OcAcksF8MfQhsoOrEfjL3ki8kO3o,33144
 pyjamas/__init__.py,sha256=lip4G10pedUVHvwJHJKaJtz2c9c1gE-Jr72BTgtOCEU,1088
 pyjamas/dragdropmainwindow.py,sha256=aMT3m8HCOGQrvhv1bE0RqAeLT1DOeukzzHrWgjwPgZ8,1793
 pyjamas/orthogonalviewswindow.py,sha256=kr2ieb2mAncVgXDbHfZNclXb_AeDUvAVxUbROG7ttKQ,4901
-pyjamas/pjscore.py,sha256=4LUJ07-F9bmlqCyWaOjs4sj_fJP7xxgLfpD-Vpa6ReY,52550
+pyjamas/pjscore.py,sha256=ef5cUYiyaT5aec_tnCgxI8diU_cT5EXIY4szZSWuCEQ,52550
 pyjamas/pjseventfilter.py,sha256=EKkqnokHkE3uaN71A1-SQnRgjd46eUwcJNlftBw8T3g,32616
 pyjamas/pjsthreads.py,sha256=9Y-1o6eXH5arV9hVAz6oOzUhqowtE084xtQ2cnle8qk,2123
 pyjamas/pyjamas.tif,sha256=qmuNwZsHpyEAX606oz8W1JQq8HXtDGc9ZZ65yFos4Zc,2950837
 pyjamas/rutils.py,sha256=gtLoa3ViUkDx_Ba-l0l6bCMDu0zrQjQSRFmByQUxoaE,26659
 pyjamas/dialogs/__init__.py,sha256=O3kC1DwPHthI3izurSb-nCQh1aFY0bdQ9I-CD9iLiuY,1645
 pyjamas/dialogs/adjustcontrast.py,sha256=bCwwQ7uZ4eLoCLFu0Gb5s2EWfVceHBQ0lYcEkpMsAis,17513
 pyjamas/dialogs/batchanalysis.py,sha256=DDBeqnDGy4RKxerE7p2jfRH67n85eOz2rjIfouDG3TY,28797
@@ -43,15 +43,15 @@
 pyjamas/rcallbacks/rcbio.py,sha256=QCU90HA27V2tz0hHgc4kIssBWviqzkE9J_98i-FyaRI,52722
 pyjamas/rcallbacks/rcbmeasure.py,sha256=tEODUbQjwMaK9bTYxgqzvwYGSuNF1H9CqfcCpSxEopw,11288
 pyjamas/rcallbacks/rcboptions.py,sha256=J_-0EodMho_FyFMeG_BFMReClEm42ulis_lb9pLblfs,12556
 pyjamas/rcallbacks/rcbplugins.py,sha256=bRbOJ7zMPCTzjKJk3jnYTEEJrCIYP3geh_iWfrIA_Hk,3617
 pyjamas/rimage/__init__.py,sha256=BiL1mv2uql78UIxsar5UzSQMDFRy0JQskioHL4kW-a4,913
 pyjamas/rimage/csgraph.py,sha256=rMu8OgTx-uvIaRM78KGug7T_KEVLE4xWSkTo4CxFQQo,3091
 pyjamas/rimage/rimcore.py,sha256=50mFbTaUxQMiORfds4VPRudZF5RRUD-8COtlVFzmlkw,3799
-pyjamas/rimage/rimutils.py,sha256=KJa90czZUgw3kyLFgzFgu6NS5_jW8zEi3aJ7x46L3MA,67122
+pyjamas/rimage/rimutils.py,sha256=LFZ5Gwz5feqnblLyVWecHkBvAarvfjkhfAumL_Ma4zo,67108
 pyjamas/rimage/rimml/__init__.py,sha256=O5rqK4O5d96Y61cB_6PbmmvG2HQuUcHO4xpALn-z3fE,1484
 pyjamas/rimage/rimml/batchclassifier.py,sha256=WwjxeNy2uTF5sKhrific48uMAN64QzOLFiVlNhXy-5g,3557
 pyjamas/rimage/rimml/batchml.py,sha256=3cdNyWRtJ8FjB3yi9jjoY_kgN89e_lh32aAep1GhYjk,1585
 pyjamas/rimage/rimml/batchneuralnet.py,sha256=HCnm71qYfUZQlQhAyrmTZdW7IuQT2PShYxEheHktCjU,2740
 pyjamas/rimage/rimml/batchrecurrentneuralnet.py,sha256=ZEqDYU_1M4vbACOnUWKLRBkg6ULftzk-DWy0ILYMF78,7409
 pyjamas/rimage/rimml/classifier_types.py,sha256=SbDTTr5jh4In_pnHthUs0MCSJQvWc6E_dl3HVc7FLEQ,275
 pyjamas/rimage/rimml/featurecalculator.py,sha256=y8N9ug8RtvhEuJYDvVRGYVpC-yoSkiQDxFm9zTkIpAw,1173
@@ -59,23 +59,23 @@
 pyjamas/rimage/rimml/featurecalculator_rowofpixels.py,sha256=JNfu-6UYGpQo2KQrfqwP2kHN4XwkKvUoTpkOpMdJDek,1289
 pyjamas/rimage/rimml/featurecalculator_sog.py,sha256=j_VTupYS9DQz7hBXAIioCRli5mZ01Nr3Qb7-BaqSN00,3196
 pyjamas/rimage/rimml/rimclassifier.py,sha256=Kw56mewnfaRWtBJGK0q9mZpi7Sgnzl7-2iUYP8O5CJc,17339
 pyjamas/rimage/rimml/rimlr.py,sha256=-M6mrwJn9zwbbZ9J9ceCsv0d2Au4KUPA_-hRyCCXAok,1824
 pyjamas/rimage/rimml/rimml.py,sha256=9wm8gufvWLuszQpbEEBQJSP6Rzwex2owaZbwUYjj3-I,1382
 pyjamas/rimage/rimml/rimneuralnet.py,sha256=k6BrG7gcsgG08GTKs8FfZ37JUGqOLSaMxI7vOH9umAk,1857
 pyjamas/rimage/rimml/rimrecurrentneuralnet.py,sha256=MIM6IgqC-lbXiYcLjJEWPNRqYUu7Cv8nmsuZh2Zc4Xo,1960
-pyjamas/rimage/rimml/rimrescunet.py,sha256=xv0BDhFwfKl-EQl6lC0nQkVrLHLmYr-3cVfGdy6u_9c,20936
+pyjamas/rimage/rimml/rimrescunet.py,sha256=tY13oRkgFH8fvPG_EfCY0WvwVETnCNbWijAeeQ1WMDQ,20979
 pyjamas/rimage/rimml/rimsvm.py,sha256=ZXYAwbWL2I39nDmXXqntbXRX0AwCBu8uda-XRiODtKk,2084
-pyjamas/rimage/rimml/rimunet.py,sha256=K-feheZFy9IEf3TnIpyzkc5OunID0lqsxjfbndmCqyQ,15137
+pyjamas/rimage/rimml/rimunet.py,sha256=oXUPj-CT9wXf4dO9QsGAsVYKACsgHgenVG4Gpi22Usc,15508
 pyjamas/rplugins/__init__.py,sha256=aHh9B0OVLt-7rJyyoXV0t7NMoziJODn279yaHZrF5h4,847
 pyjamas/rplugins/base.py,sha256=d1zP7iq85pkTgAQMnF39XILFJ2xE7Thdr0qlLEUQ0zU,1249
 pyjamas/tests/__init__.py,sha256=8l38RxqL4YvU35uHcp58t2qPDGy7nUgHz8sXpVr_X3A,796
 pyjamas/tests/conftest.py,sha256=Mi4BlSPuKkO4QBPpE6fh8K8jSrPq6Vr4TgqricNrnJo,857
 pyjamas/tests/unit/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pyjamas/tests/unit/pjsfixtures.py,sha256=qu4exl-A_MaMTmLXmOeX3v8uKpL-tyYbJ2e94_0h8IA,5952
-pyjamas/tests/unit/test_image.py,sha256=Il8WThmdx1FnpDfb7hOA7CGPsf0FBLHYBysjzFXIKeg,11306
-pyjamas/tests/unit/test_io.py,sha256=u3v_uKXuCAPKpj9S8GvwERGFkq916m02RNEcsFVxs_U,17400
-pyjamas_rfglab-2023.6.0.dist-info/METADATA,sha256=MJzwtSv_nHnpWn4YrbXhbcl1f83e8bAqpbfsxBt9-8Y,8308
-pyjamas_rfglab-2023.6.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-pyjamas_rfglab-2023.6.0.dist-info/entry_points.txt,sha256=Kz2XxZBSSzrf8qtxDZPgWAw2aV48mIiIL1tLbMpFfV0,50
-pyjamas_rfglab-2023.6.0.dist-info/top_level.txt,sha256=1JrBnRcgMVjhVrxaCoReIJTpPg7PPqhjjzehykIDu_A,8
-pyjamas_rfglab-2023.6.0.dist-info/RECORD,,
+pyjamas/tests/unit/pjsfixtures.py,sha256=_0U4FhwxdbD1l0qApKMCiqSvCyjPFV-5Ju7AM_TOxss,6326
+pyjamas/tests/unit/test_image.py,sha256=50npP6d9E_uJBhDjnUJ0_L_aVO6zhBTOtQuq5N7ZBJ0,12486
+pyjamas/tests/unit/test_io.py,sha256=mdJTX89_9P5TfkS68mMBFC1fzsSdpDAcrVbl0MNf350,16795
+pyjamas_rfglab-2023.7.1.dist-info/METADATA,sha256=hgM4V9jOPZSiJUsw4OJZUYC2jQHibZs6A8OKPsS-3LY,2312
+pyjamas_rfglab-2023.7.1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+pyjamas_rfglab-2023.7.1.dist-info/entry_points.txt,sha256=ia7GtnsWENwAPDp8BCR8IN23N9MEZyvBZBczVjDvr-k,49
+pyjamas_rfglab-2023.7.1.dist-info/top_level.txt,sha256=1JrBnRcgMVjhVrxaCoReIJTpPg7PPqhjjzehykIDu_A,8
+pyjamas_rfglab-2023.7.1.dist-info/RECORD,,
```

